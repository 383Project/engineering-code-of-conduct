# Responsible Use of AI Policy

## Introduction

This policy outlines the guidelines and best practices for the responsible use of Artificial Intelligence (AI) within our engineering team. AI is a significant part of the industry we operate in, and this policy aims to embrace and encourage its usage while ensuring the protection of sensitive information and maintaining ethical standards.

## Embracing AI Usage

We acknowledge the importance of AI in our workplace and encourage its usage for various engineering tasks and projects. AI technologies can enhance efficiency, productivity, and innovation within our team.

## Protection of Sensitive Data

1. Data entered into AI services, such as ChatGPT, must not contain any sensitive information. This includes personal, confidential, or proprietary data. It is crucial to ensure that AI services are not exposed to sensitive data to mitigate potential privacy or security risks.

2. Engineering team members should exercise caution when sharing data with AI services and ensure compliance with data protection regulations, industry standards, and client requirements.

## Trialing AI-Related Software

1. It is permissible for team members to trial AI-related software to explore its potential benefits for our engineering projects. However, it is important to inform your line manager about the intention and purpose of the trial.

2. Trialing AI-related software should be done in a controlled and responsible manner, adhering to applicable regulations and policies.

## Approval for Using AI Technologies

1. If a team or individual intends to use an AI technology within the engineering team once trialed, they must seek approval from the Data Security Officer.

2. The Data security office will assess the proposed AI technology to ensure it aligns with our data protection and security requirements.

## Responsible Use of ChatGPT

1. The use of ChatGPT within our business is generally accepted for work purposes, provided the following guidelines are followed:

   a. Information generated by ChatGPT should not be taken at face value and must be subjected to external fact-checking before being considered accurate or reliable.

   b. When programming using ChatGPT, it should not be used for making decisions that directly impact code, social platforms, or any interactions with customers or sensitive data. Human oversight and verification are necessary for critical decision-making.

   c. Outputs from ChatGPT must not be made public-facing unless they have undergone comprehensive testing and validation to ensure accuracy and appropriateness.

## Conclusion

The responsible use of AI technologies is crucial to maintain ethical standards, protect sensitive data, and ensure accurate decision-making. By following this policy, we can leverage the benefits of AI while upholding our commitment to data privacy, security, and customer trust.

Please note that this policy is subject to periodic review and may be updated to reflect changes in industry standards, regulations, or organizational requirements.

As this is a growing technology which is not yet reglated this guidance is subject to change inline with future regulations that apply within the countries whom we opperate our applications for.

